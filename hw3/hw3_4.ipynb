{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Character Level Text Generation\n",
    "You will implement a multi-layer Recurrent Neural Network (RNN, LSTM, and GRU) for training/sampling from character-level language models, which takes one text file as input and trains an RNN that learns to predict the next character in a sequence. The RNN can then be used to generate text character by character that will look like the original training data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import timeit\n",
    "import os\n",
    "from six.moves import cPickle\n",
    "from text_utils import TextLoader\n",
    "from tensorflow.contrib import rnn\n",
    "from char_rnn_model import Model\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # read data from file and save preprocessed data\n",
    "# T = TextLoader()\n",
    "# T.read_data('shakespeare.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data using TextLoader object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = np.load('s_data/train.npy')\n",
    "val = np.load('s_data/val.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read vocab dict back from the file\n",
    "pkl_file = open('s_data/vocab.pkl', 'rb')\n",
    "vocab = cPickle.load(pkl_file)\n",
    "pkl_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read vocab dict back from the file\n",
    "pkl_file = open('s_data/inverse_vocab.pkl', 'rb')\n",
    "inverse_vocab = cPickle.load(pkl_file)\n",
    "pkl_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{',': 23, \"'\": 36, 'C': 6, '?': 32, 'G': 57, 'P': 53, 'a': 19, '&': 60, '-': 47, 'u': 21, 'e': 8, '\\n': 11, 'c': 17, '$': 64, 'w': 15, ';': 41, 'I': 38, 'D': 52, 'b': 42, 'F': 0, 'x': 55, 'y': 20, 'd': 18, 'S': 29, 'm': 24, '3': 63, 'T': 48, 'O': 44, 'A': 27, 't': 4, 'h': 22, 'z': 7, 'i': 1, ' ': 5, 'H': 49, 'v': 31, 'o': 14, 'L': 37, 'R': 33, 'J': 56, 'q': 54, 'B': 12, 'W': 35, 'U': 51, ':': 10, 'Y': 30, 'r': 2, 'X': 62, 'M': 34, 'Z': 61, ']': 66, 'j': 45, 'l': 28, 'N': 39, 'Q': 59, 'g': 40, 'E': 50, 'k': 25, 'n': 9, 'p': 16, '!': 43, '[': 65, 'f': 13, 'K': 58, 's': 3, 'V': 46, '.': 26}\n",
      "{0: 'F', 1: 'i', 2: 'r', 3: 's', 4: 't', 5: ' ', 6: 'C', 7: 'z', 8: 'e', 9: 'n', 10: ':', 11: '\\n', 12: 'B', 13: 'f', 14: 'o', 15: 'w', 16: 'p', 17: 'c', 18: 'd', 19: 'a', 20: 'y', 21: 'u', 22: 'h', 23: ',', 24: 'm', 25: 'k', 26: '.', 27: 'A', 28: 'l', 29: 'S', 30: 'Y', 31: 'v', 32: '?', 33: 'R', 34: 'M', 35: 'W', 36: \"'\", 37: 'L', 38: 'I', 39: 'N', 40: 'g', 41: ';', 42: 'b', 43: '!', 44: 'O', 45: 'j', 46: 'V', 47: '-', 48: 'T', 49: 'H', 50: 'E', 51: 'U', 52: 'D', 53: 'P', 54: 'q', 55: 'x', 56: 'J', 57: 'G', 58: 'K', 59: 'Q', 60: '&', 61: 'Z', 62: 'X', 63: '3', 64: '$', 65: '[', 66: ']'}\n"
     ]
    }
   ],
   "source": [
    "print(vocab)\n",
    "print(inverse_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "char = list(vocab.keys())\n",
    "vocab_size = len(char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67\n"
     ]
    }
   ],
   "source": [
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "def batch_generator(data,batch_size,num_seq):\n",
    "    data1 = copy.deepcopy(data)\n",
    "    # generate sequence\n",
    "    x_s = []\n",
    "    y_s = []\n",
    "    for i in range(len(data)-num_seq-1):\n",
    "        x_s.append(data1[i:i+num_seq])\n",
    "        y_s.append(data1[i+1:i+num_seq+1])\n",
    "        i += num_seq\n",
    "        \n",
    "    # generate batch    \n",
    "    start_idx = 0\n",
    "    end_idx = batch_size\n",
    "    while end_idx < len(data):\n",
    "        x = np.reshape(x_s[start_idx:end_idx],(batch_size,num_seq,1))\n",
    "        y = np.reshape(y_s[start_idx:end_idx],(batch_size,num_seq))\n",
    "        yield(x,y)\n",
    "        start_idx += batch_size\n",
    "        end_idx += batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define directories, hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 3\n",
    "#unrolled through time steps\n",
    "seq_len=7\n",
    "#hidden LSTM units\n",
    "rnn_size=100\n",
    "\n",
    "# number of lstm layer\n",
    "num_layers = 3\n",
    "\n",
    "#learning rate for adam\n",
    "learning_rate=0.001\n",
    "\n",
    "\n",
    "#size of batch\n",
    "batch_size=128\n",
    "\n",
    "# keep probability\n",
    "keep_prob = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create your model object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jupyter/hw3/char_rnn_model.py:61: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From /home/jupyter/hw3/char_rnn_model.py:64: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From /home/jupyter/hw3/char_rnn_model.py:70: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/tensor_array_ops.py:162: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/rnn_cell_impl.py:1259: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "model = Model(batch_size, seq_len, rnn_size, num_layers, learning_rate, vocab_size, keep_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in path: checkpoint/model1.ckpt\n",
      "Epoch1 validation accuracy= 0.31114\n",
      "Model saved in path: checkpoint/model1.ckpt\n",
      "Epoch2 validation accuracy= 0.32491\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for i in range(1,epoch+1):\n",
    "        #fetch batch\n",
    "        training_data = batch_generator(train,batch_size,seq_len)\n",
    "        a = 0\n",
    "        for t_data, labels in training_data:\n",
    "            f_dict = {model.X: t_data, model.Y: labels}\n",
    "            sess.run(model.train_op, feed_dict=f_dict)\n",
    "\n",
    "        save_path = saver.save(sess, \"checkpoint/model1.ckpt\")\n",
    "        print(\"Model saved in path: %s\" % save_path)\n",
    "\n",
    "        a = 0\n",
    "        correct= 0\n",
    "        validation_data = batch_generator(val, batch_size,seq_len)\n",
    "        for v_data, labels in validation_data:\n",
    "#             a = a+1\n",
    "#             if a==20: break\n",
    "            f_dict = {model.X: v_data, model.Y: labels}\n",
    "            correct += sess.run(model.num_correct, feed_dict=f_dict)\n",
    "        val_acc = correct/(val.shape[0]*7*1.0)\n",
    "\n",
    "\n",
    "        print('Epoch'+str(i),\"validation accuracy= {:.5f}\".format(val_acc))\n",
    "\n",
    "\n",
    "print(\"Training finished!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#size of batch\n",
    "batch_size=1 \n",
    "\n",
    "model = Model(batch_size, seq_len, rnn_size, num_layers, learning_rate, vocab_size, keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(sess, vocab, vocab_reverse, n, start):\n",
    "        \n",
    "        # covert the input to index\n",
    "        split = [vocab[i] for i in start]\n",
    "           \n",
    "        for i in range(n):\n",
    "            length = len(split)\n",
    "            \n",
    "            #get the last seq_len elements of the sequence\n",
    "            piece = split[length - seq_len : length]\n",
    "            \n",
    "            batch_x = [piece]\n",
    "            batch_x = np.reshape(batch_x,[1,seq_len,1])\n",
    "\n",
    "            next_chars = sess.run(logits, feed_dict={X:batch_x})[:,-1,:]\n",
    "            val = np.argmax(next_chars)\n",
    "            split.append(val) # generate new input \n",
    "\n",
    "        # change the prediction from idx to character\n",
    "        string_back = []\n",
    "        for i in range(len(split)):\n",
    "            val = split[i] \n",
    "            string_back.append(vocab_reverse[val])\n",
    "            \n",
    "        \n",
    "        return \"\".join(string_back)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoint/model.ckpt\n",
      "queen then the lords the hand the the the tond the see the throw have the that the sarry the the recond Lo me the the sour the come the the rear the speet the for the sou the the so the pomet the the that the the the the soer and the send the word the the so the man the seed the lesse the say the son the meen\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "  # Restore variables from disk.\n",
    "    saver.restore(sess, \"checkpoint/model.ckpt\")\n",
    "    a = model.sample(sess, vocab, inverse_vocab, 300, 'queen then')\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "The network can predict correct word, but  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
